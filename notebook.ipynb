{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "fXHy3UQWBaGF"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "# -------\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pydicom import dcmread\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "yTg6rOYPp1mM"
      },
      "outputs": [],
      "source": [
        "# BEAT IDENTIFICATION\n",
        "# -------------------\n",
        "\n",
        "def find_beats(video):\n",
        "    \"\"\" Description: Returns a list of frames where beats start in the video\n",
        "        Input: A video (sequence of RGB images)\n",
        "        Output: A list containing the indices of frames in the video that are the start of a heartbeat\n",
        "    \"\"\"\n",
        "    signal_height = find_signal_height(video)\n",
        "    beats = [i for i in range(len(video)) if is_beat(video[i], signal_height)]\n",
        "    \n",
        "    # condense nearby beats into first one\n",
        "    i = 1\n",
        "    last_frame = beats[0]\n",
        "    while i < len(beats):\n",
        "        if beats[i] - last_frame < 2:\n",
        "            last_frame = beats[i]\n",
        "            del beats[i]\n",
        "        else:\n",
        "            last_frame = beats[i]\n",
        "            i += 1\n",
        "\n",
        "    return beats\n",
        "\n",
        "\n",
        "def find_signal_height(video):\n",
        "    \"\"\" Description: Finds the typical height of heartbeat spike for a video (Helper for find_beats)\n",
        "        Input: A video (sequence of RGB images)\n",
        "        Output: An integer number of pixels indicating the typical height of a heartbeat peak\n",
        "    \"\"\"\n",
        "    pcts = []\n",
        "    for img in video:\n",
        "        mask = signal_mask(img)\n",
        "        x, _, _ = locate_line(mask)\n",
        "        mask[:, x-4:x+4] = 0  # remove vertical line for location in signal\n",
        "        ys, _ = np.where(mask > 0)\n",
        "        y = np.median(ys) # use median y-position of pixels for baseline of signal\n",
        "        pcts.append(max(abs(y - np.percentile(ys, 5)), abs(y - np.percentile(ys, 95)))) # use highest and lowest 5% marks for height\n",
        "    signal_height = int(np.mean(pcts))\n",
        "    return signal_height \n",
        "\n",
        "\n",
        "def is_beat(img, signal_height=None):\n",
        "    \"\"\" Description: Returns True if image contains a beat and False otherwise (Helper for find_beats)\n",
        "        Input: An RGB image and an optional height for typical heartbeat peak in pixels\n",
        "        Output: True if frame overlaps with a heartbeat and False otherwise\n",
        "    \"\"\"\n",
        "    mask = signal_mask(img)\n",
        "    x, y, h = locate_line(mask)\n",
        "    mask = mask//255\n",
        "\n",
        "    # remove any extra of vertical line\n",
        "    end = x\n",
        "    while np.sum(mask[y-h:y+h, end]) == 2*h and end > 0:\n",
        "        end -= 1\n",
        "\n",
        "    # look at region to left of vertical green line\n",
        "    target = mask[y-h:y+h, end-5:end]\n",
        "\n",
        "    # if vertical variance of horizontal line exceeds threshold, consider it a beat\n",
        "    ys, _ = np.where(target > 0)\n",
        "    is_a_beat = np.var(ys) > 5\n",
        "\n",
        "    # require line to also be a certain percentage of typical peak height if provided\n",
        "    if signal_height is not None:\n",
        "        is_a_beat = is_a_beat and (np.sum(target[:h-int(0.5*signal_height),:]) > 0 or np.sum(target[h+int(0.5*signal_height):,:]) > 0) \n",
        "\n",
        "    return is_a_beat\n",
        "\n",
        "\n",
        "def signal_mask(img):\n",
        "    \"\"\" Description: Returns mask containing only the green heartbeat signal (Helper for is_beat)\n",
        "        Input: An RGB image \n",
        "        Output: A binary image containing the heartbeat signal\n",
        "    \"\"\"\n",
        "    mask = cv2.inRange(cv2.cvtColor(img, cv2.COLOR_RGB2HSV), (30, 10, 50), (90, 255, 255))  # filter for green signal\n",
        "    mask[:600,:] = 0 # remove all noise clearly from above the signal\n",
        "    return mask\n",
        "\n",
        "\n",
        "def locate_line(mask):\n",
        "    \"\"\" Description: Returns coordinates of current location in signal (Helper for is_beat)\n",
        "        Input: A binary image containing heartbeat signal (output of signal_mask)\n",
        "        Output: X and Y coordinates of signal, as well as the signal's height\n",
        "    \"\"\"\n",
        "    mask = np.array(mask)\n",
        "\n",
        "    # find the y position of the horizontal green signal\n",
        "    ys, _ = np.where(mask[:,:] > 0)\n",
        "    y = int(np.median(ys))\n",
        "\n",
        "    # remove the horizontal line, leaving just the top of the vertical green line\n",
        "    mask[650:,:] = 0\n",
        "\n",
        "    # identify the line (approximately)\n",
        "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "    x,_,w,h = max([cv2.boundingRect(c) for c in contours], key=lambda b: b[3])\n",
        "\n",
        "    # remove all noise from outside the relevant area\n",
        "    mask[:, x+w:] = 0\n",
        "    mask[:, :x-w] = 0\n",
        "\n",
        "    # find the x position of the vertical green signal\n",
        "    _, xs = np.where(mask[:,:] > 0)\n",
        "    x = int(np.mean(xs))\n",
        "\n",
        "    return x, y, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "umvEjQzuJ7EK",
        "outputId": "9dfe4289-3051-46a1-fd46-406ce8abef93"
      },
      "outputs": [],
      "source": [
        "# CYCLE NORMALIZATION\n",
        "# -------------------\n",
        "\n",
        "def normalize(video, sec_per_cycle, name):\n",
        "    \"\"\" Description: Sets each cycle in a heartbeat video to the same length\n",
        "        Input: A video (sequence of RGB images), the number of seconds per heartbeat cycle, and a name to save to\n",
        "        Output: Returns the number of heart cycles in the normalized video, saves video to computer\n",
        "    \"\"\"\n",
        "    beats = find_beats(video)\n",
        "    beat_videos = split_video(video, beats)\n",
        "\n",
        "    # write out individual cycle videos\n",
        "    for i in range(len(beat_videos)):\n",
        "        vid = beat_videos[i]\n",
        "        num_frames = len(vid)\n",
        "        fps = num_frames / sec_per_cycle\n",
        "        write_video(f\"./{name}-{i}.avi\", vid, fps)\n",
        "\n",
        "    # combine into single video\n",
        "    vids = \"|\".join([f\"./{name}-{i}.avi\" for i in range(len(beat_videos))])\n",
        "    os.system(f\"ffmpeg -i 'concat:{vids}' -c copy ./{name}.avi\")\n",
        "\n",
        "    # delete old individual videos\n",
        "    for i in range(len(beat_videos)):\n",
        "        os.remove(f\"./{name}-{i}.avi\")\n",
        "    \n",
        "    return len(beat_videos)\n",
        "\n",
        "\n",
        "def split_video(video, beats):\n",
        "    \"\"\" Description: Splits video into segments each containing a single heart beat cycle (Helper for normalize_cycles)\n",
        "        Input: A video (sequence of RGB images) and a list of beats (output of find_beats)\n",
        "        Output: A list of videos, each video containing a single complete heartbeat cycle\n",
        "    \"\"\"\n",
        "    beat_videos = []\n",
        "    for i in range(1, len(beats)):\n",
        "        beat_videos.append(video[beats[i-1]:beats[i]])\n",
        "    return beat_videos\n",
        "\n",
        "\n",
        "def write_video(fname, video, fps):\n",
        "    \"\"\" Description: Saves a video to file with a given fps\n",
        "        Input: Filename, a video (sequence of RGB images), and an fps\n",
        "        Output: None, saves video to computer\n",
        "    \"\"\"\n",
        "    h,w = video[0].shape[:2] \n",
        "    fourcc = cv2.VideoWriter.fourcc(*'MJPG')\n",
        "    out = cv2.VideoWriter(fname, fourcc, fps, (w, h))\n",
        "    for img in video:\n",
        "        out.write(img)\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VIDEO ALIGNMENT\n",
        "# ---------------\n",
        "\n",
        "def align_videos(fnames, sec_per_cycle, names=[]):\n",
        "    \"\"\" Description: Normalizes and trims videos to same length\n",
        "        Input: List of video paths, the number of seconds a cycle should last, and a list of names to save the videos as\n",
        "        Output: None, saves the set of normalized and trimmed videos to computer\n",
        "    \"\"\"\n",
        "    if len(names) != len(fnames):\n",
        "        names = [fname.split('/')[-1].split('.')[0] for fname in fnames]\n",
        "    min_cycle_count = normalize_videos(fnames, sec_per_cycle, names)\n",
        "    min_secs = min_cycle_count * sec_per_cycle\n",
        "    trim_videos(names, min_secs)\n",
        "    \n",
        "\n",
        "def normalize_videos(fnames, sec_per_cycle, names=[]):\n",
        "    \"\"\" Description: Normalizes a set of videos\n",
        "        Input: List of video paths, the number of seconds a cycle should last, and a list of names to save the videos as\n",
        "        Output: Returns the number of cycles in the shortest video and saves the normalized videos to computer\n",
        "    \"\"\"\n",
        "    if len(names) != len(fnames):\n",
        "        names = [fname.split('/')[-1].split('.')[0] for fname in fnames]\n",
        "    num_cycles = []\n",
        "    for fname, name in zip(fnames, names):\n",
        "        video = load_video(fname)\n",
        "        cycle_count = normalize(video, sec_per_cycle, name)\n",
        "        num_cycles.append(cycle_count)\n",
        "    return min(num_cycles)\n",
        "\n",
        "\n",
        "def trim_videos(names, sec, delete_old=True):\n",
        "    \"\"\" Description: Trims a set of videos to a specified integer number of seconds\n",
        "        Input: A list of video names, the number of seconds to trim to, and an optional boolean to indicate deleting the old videos\n",
        "        Output: None, saves trimmed videos to computer\n",
        "    \"\"\"\n",
        "    max_time = time.strftime('%H:%M:%S', time.gmtime(sec))\n",
        "    for name in names:\n",
        "        os.system(f\"ffmpeg -i {name}.avi -ss 00:00:00 -t {max_time} -c:v copy -c:a copy {name}_trimmed.avi\")\n",
        "        if delete_old:\n",
        "            os.remove(f\"./{name}.avi\")\n",
        "            os.system(f\"mv ./{name}_trimmed.avi ./{name}.avi\")\n",
        "\n",
        "\n",
        "def load_video(fname):\n",
        "    \"\"\" Description: Loads a video from a filename\n",
        "        Input:  The filename of a video (string)\n",
        "        Output: The video (sequence of RGB images)\n",
        "    \"\"\"\n",
        "    video = [img for img in dcmread(fname).pixel_array]\n",
        "    return video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXAMPLE\n",
        "# -------\n",
        "\n",
        "data_path = './data'\n",
        "\n",
        "patients = [\"10026_20171208\", \n",
        "            \"10651_20171118\", \n",
        "            \"14369_20180420\", \n",
        "            \"15751_20180728\", \n",
        "            \"20198_20180511\", \n",
        "            \"20218_20171201\", \n",
        "            \"20596_20171118\", \n",
        "            \"21104_20180322\", \n",
        "            \"22444_20180404\"]\n",
        "\n",
        "indices = [[\"02\", \"03\", \"04\"],\n",
        "           [\"02\", \"03\"],\n",
        "           [\"41\", \"42\"],\n",
        "           [\"02\", \"03\"],\n",
        "           [\"03\", \"04\"],\n",
        "           [\"02\", \"05\", \"06\", \"07\"],\n",
        "           [\"02\", \"03\"],\n",
        "           [\"02\", \"03\", \"04\"],\n",
        "           [\"02\", \"03\", \"04\"]]\n",
        "\n",
        "video_paths = sum([[f\"{data_path}/{patients[i]}/IM-0001-00{index}.dcm\" for index in indices[i]] for i in range(len(patients))], [])\n",
        "video_names=[f\"video{i}\" for i in range(len(video_paths))]\n",
        "\n",
        "align_videos(video_paths, 2, video_names)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ecg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
